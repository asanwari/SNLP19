{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# SNLP - SoSe 2019 - ASSINGMENT v\n",
    "\n",
    "import math\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "%matplotlib qt \n",
    "\n",
    "def word_ngrams(tokenized_text, n):\n",
    "    return [tuple(tokenized_text[i:i + n]) for i in range(0, len(tokenized_text)-n+1)]\n",
    "\n",
    "def tokenize(text):\n",
    "    \"List all the word tokens (consecutive letters) in a text. Normalize to lowercase.\"\n",
    "    return re.findall(\"[a-z]+\", text.replace(\"'\", '').lower())\n",
    "\n",
    "class ngram_LM:\n",
    "    \"\"\"A class to represent a language model.\"\"\"\n",
    "\n",
    "    def __init__(self, n, ngram_counts, vocab, unk=False):\n",
    "        \"\"\"\"Make a n-gram language model, given a vocab and\n",
    "            data structure for n-gram counts.\"\"\"\n",
    "\n",
    "        self.n = n\n",
    "\n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.V = len(vocab)\n",
    "\n",
    "        self.ngram_counts = ngram_counts\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # START BY MAKING THE RIGHT COUNTS FOR THIS PARTICULAR self.n\n",
    "        # for unigrams, we only need total word count\n",
    "        if n == 1:\n",
    "            self.total_count = sum(self.ngram_counts.values())\n",
    "        # for bigrams, we need total count wrt each word. In our language, it is history count.\n",
    "        elif n == 2:\n",
    "            self.history_count = Counter()\n",
    "            for k, v in self.ngram_counts.items():\n",
    "                self.history_count[k[0]] = self.history_count[k[0]] + v\n",
    "            # since we only count for the first word in the tuple, we will always\n",
    "            # miss counting </s>. However, since the frequency of </s> is the same\n",
    "            # as the frequency of <s>, we can simply assign it equal to it.\n",
    "            self.history_count['</s>'] = self.history_count['<s>']\n",
    "\n",
    "\n",
    "\n",
    "    def estimate_prob(self, history, word):\n",
    "        \"\"\"Estimate probability of a word given a history.\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        if history == '':\n",
    "            # unigram\n",
    "            word_frequency = self.ngram_counts[tuple([word])]\n",
    "            return word_frequency/self.total_count\n",
    "\n",
    "        else:\n",
    "            # bigram\n",
    "            word_frequency = self.ngram_counts[tuple([history, word])]\n",
    "            history_count = self.history_count[history]\n",
    "            if history_count == 0:\n",
    "                return 0\n",
    "            return word_frequency/history_count\n",
    "\n",
    "\n",
    "    def estimate_smoothed_prob(self, history, word, alpha = 0.5):\n",
    "        \"\"\"Estimate probability of a word given a history with Lidstone smoothing.\"\"\"\n",
    "\n",
    "        if history == '':\n",
    "            # unigram\n",
    "            word_frequency = self.ngram_counts[tuple([word])]\n",
    "            return (word_frequency + alpha)/(alpha*self.V +self.total_count)\n",
    "\n",
    "        else:\n",
    "            # bigram\n",
    "            word_frequency = self.ngram_counts[tuple([history, word])]\n",
    "            history_count = self.history_count[history]\n",
    "            return (word_frequency + alpha)/(alpha*self.V + history_count)\n",
    "    \n",
    "\n",
    "    def logP(self, history, word):\n",
    "        \"\"\"Return base-2 log probablity.\"\"\"\n",
    "        prob = self.estimate_smoothed_prob(history, word)\n",
    "        log_prob = math.log(prob, 2)\n",
    "        return log_prob\n",
    "\n",
    "\n",
    "    def score_sentence(self, sentence):\n",
    "        \"\"\"Given a sentence, return score.\"\"\"\n",
    "        log_prob_sum = 0\n",
    "        for i in range(len(sentence)):\n",
    "            history = sentence[i][0]\n",
    "            word = sentence[i][1]\n",
    "            log_prob = self.logP(history, word)\n",
    "            log_prob_sum += log_prob\n",
    "        normalized_log_prob_sum = (-1 / len(sentence)) * log_prob_sum\n",
    "        return normalized_log_prob_sum\n",
    "\n",
    "\n",
    "    def test_LM(self):\n",
    "        \"\"\"Test whether or not the probability mass sums up to one.\"\"\"\n",
    "\n",
    "        precision = 10**-8\n",
    "\n",
    "        if self.n == 1:\n",
    "\n",
    "            P_sum = sum(self.estimate_prob('', w) for w in self.vocab)\n",
    "\n",
    "            assert abs(1.0 - P_sum) < precision, 'Probability mass does not sum up to one.'\n",
    "\n",
    "        elif self.n == 2:\n",
    "            histories = ['the', 'in', 'at', 'blue', 'white']\n",
    "\n",
    "            for h in histories:\n",
    "\n",
    "                P_sum = sum(self.estimate_prob(h, w) for w in self.vocab)\n",
    "\n",
    "                assert abs(1.0 - P_sum) < precision, 'Probability mass does not sum up to one for history' + h\n",
    "\n",
    "        print('TEST SUCCESSFUL!')\n",
    "\n",
    "\n",
    "\n",
    "    def test_smoohted_LM(self):\n",
    "        \"\"\"Test whether or not the smoothed probability mass sums up to one.\"\"\"\n",
    "        precision = 10**-8\n",
    "\n",
    "        if self.n == 1:\n",
    "\n",
    "            P_sum = sum(self.estimate_smoothed_prob('', w) for w in self.vocab)\n",
    "\n",
    "            assert abs(1.0 - P_sum) < precision, 'Probability mass does not sum up to one.'\n",
    "\n",
    "        elif self.n == 2:\n",
    "            histories = ['the', 'in', 'at', 'blue', 'white']\n",
    "\n",
    "            for h in histories:\n",
    "\n",
    "                P_sum = sum(self.estimate_smoothed_prob(h, w) for w in self.vocab)\n",
    "\n",
    "                assert abs(1.0 - P_sum) < precision, 'Probability mass does not sum up to one for history' + h\n",
    "\n",
    "        print('TEST SUCCESSFUL!')\n",
    "\n",
    "\n",
    "    def perplexity(self, test_corpus, alpha):\n",
    "\n",
    "        likelihood = 0\n",
    "        for sentence in test_corpus:\n",
    "            try:\n",
    "                if self.n == 1:\n",
    "                    prob = self.estimate_smoothed_prob('', sentence[0], alpha)\n",
    "                elif self.n ==2:\n",
    "                    prob = self.estimate_smoothed_prob(sentence[0], sentence[1], alpha)\n",
    "                likelihood += math.log2(prob)\n",
    "            except:\n",
    "                if alpha == 0:\n",
    "                    continue \n",
    "\n",
    "        perplexity = math.pow(2, (-1*likelihood)/len(test_corpus))\n",
    "        return perplexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dickens_filename= 'train/dickens.en.train'\n",
    "doyle_filename = 'train/doyle.en.train'\n",
    "twain_filename = 'train/twain.en.train'\n",
    "\n",
    "with open(dickens_filename, encoding='utf-8', errors='replace') as f:\n",
    "    # read entire file\n",
    "    dickens_text = f.read() \n",
    "    f.close()\n",
    "with open(doyle_filename, encoding='utf-8', errors='replace') as f:\n",
    "    # read entire file\n",
    "    doyle_text = f.read() \n",
    "    f.close()\n",
    "with open(twain_filename, encoding='utf-8', errors='replace') as f:\n",
    "    # read entire file\n",
    "    twain_text = f.read() \n",
    "    f.close()\n",
    "\n",
    "dickens_sent = nltk.sent_tokenize(dickens_text)\n",
    "doyle_sent = nltk.sent_tokenize(doyle_text)\n",
    "twain_sent = nltk.sent_tokenize(twain_text)\n",
    "\n",
    "tokenized_dickens = []\n",
    "tokenized_doyle = []\n",
    "tokenized_twain = []\n",
    "\n",
    "for sent in dickens_sent:\n",
    "    tokenized_dickens.extend(tokenize(sent))\n",
    "    \n",
    "for sent in doyle_sent:\n",
    "    tokenized_doyle.extend(tokenize(sent))\n",
    "    \n",
    "for sent in twain_sent:\n",
    "    tokenized_twain.extend(tokenize(sent))\n",
    "\n",
    "dickens_unigrams = word_ngrams(tokenized_dickens, 1)\n",
    "doyle_unigrams = word_ngrams(tokenized_doyle, 1)\n",
    "twain_unigrams = word_ngrams(tokenized_twain, 1)\n",
    "\n",
    "dickens_bigrams = word_ngrams(tokenized_dickens, 2)\n",
    "doyle_bigrams = word_ngrams(tokenized_doyle, 2)\n",
    "twain_bigrams = word_ngrams(tokenized_twain, 2)\n",
    "\n",
    "dickens_unigram_counts = Counter(dickens_unigrams)\n",
    "doyle_unigram_counts = Counter(doyle_unigrams)\n",
    "twain_unigram_counts = Counter(twain_unigrams)\n",
    "\n",
    "dickens_bigram_counts = Counter(dickens_bigrams)\n",
    "doyle_bigram_counts = Counter(doyle_bigrams)\n",
    "twain_bigram_counts = Counter(twain_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dickens top 15 unigrams: [(('the',), 65439), (('and',), 50578), (('to',), 36773), (('of',), 36288), (('a',), 28847), (('i',), 25128), (('in',), 24195), (('that',), 18049), (('was',), 17260), (('he',), 16283), (('it',), 16088), (('his',), 15937), (('her',), 12926), (('with',), 12582), (('you',), 11696)]\n",
      "Doyle top 15 unigrams: [(('the',), 72028), (('of',), 34862), (('and',), 34405), (('a',), 31079), (('to',), 30829), (('i',), 30810), (('that',), 21445), (('in',), 21171), (('it',), 20715), (('was',), 18734), (('he',), 17945), (('you',), 16908), (('his',), 14661), (('is',), 12663), (('had',), 11265)]\n",
      "Twain top 15 unigrams: [(('the',), 67252), (('and',), 59973), (('a',), 34946), (('to',), 33282), (('of',), 30456), (('i',), 24367), (('it',), 23727), (('was',), 20762), (('in',), 19609), (('he',), 18230), (('that',), 16879), (('you',), 12025), (('his',), 10684), (('but',), 10439), (('for',), 10150)]\n",
      "Dickens top 15 bigrams: [(('of', 'the'), 6563), (('in', 'the'), 6147), (('to', 'the'), 3511), (('to', 'be'), 2981), (('it', 'was'), 2620), (('on', 'the'), 2567), (('and', 'the'), 2441), (('in', 'a'), 2257), (('with', 'a'), 2136), (('of', 'his'), 2071), (('at', 'the'), 2062), (('he', 'was'), 2032), (('i', 'am'), 1987), (('he', 'had'), 1928), (('i', 'have'), 1888)]\n",
      "Doyle top 15 bigrams: [(('of', 'the'), 8871), (('in', 'the'), 6018), (('it', 'was'), 4071), (('to', 'the'), 3596), (('it', 'is'), 3294), (('i', 'have'), 2767), (('at', 'the'), 2718), (('that', 'i'), 2394), (('and', 'the'), 2265), (('upon', 'the'), 2116), (('on', 'the'), 2102), (('and', 'i'), 2047), (('was', 'a'), 2019), (('he', 'was'), 2006), (('to', 'be'), 1973)]\n",
      "Twain top 15 bigrams: [(('of', 'the'), 7034), (('in', 'the'), 5637), (('it', 'was'), 3687), (('and', 'the'), 3215), (('to', 'the'), 3166), (('he', 'was'), 2459), (('was', 'a'), 2229), (('on', 'the'), 2176), (('in', 'a'), 1936), (('i', 'was'), 1868), (('to', 'be'), 1850), (('it', 'is'), 1816), (('of', 'a'), 1803), (('and', 'i'), 1698), (('and', 'then'), 1670)]\n"
     ]
    }
   ],
   "source": [
    "print('Dickens top 15 unigrams:', dickens_unigram_counts.most_common(15))\n",
    "print('Doyle top 15 unigrams:', doyle_unigram_counts.most_common(15))\n",
    "print('Twain top 15 unigrams:', twain_unigram_counts.most_common(15))\n",
    "\n",
    "print('Dickens top 15 bigrams:', dickens_bigram_counts.most_common(15))\n",
    "print('Doyle top 15 bigrams:', doyle_bigram_counts.most_common(15))\n",
    "print('Twain top 15 bigrams:', twain_bigram_counts.most_common(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We don't see a noticeable difference between either the unigrams or bigrams of the three authors. This is because the most frequent unigrams and bigrams are not related to the content of the text but the language itself. Since all three are in English, we expect to see the same most frequent unigrams and bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dickens_unigram_lm = ngram_LM(1, dickens_unigram_counts, dickens_unigram_counts.keys())\n",
    "dickens_bigram_lm = ngram_LM(2, dickens_bigram_counts, dickens_unigram_counts.keys())\n",
    "doyle_unigram_lm = ngram_LM(1, doyle_unigram_counts, doyle_unigram_counts.keys())\n",
    "doyle_bigram_lm = ngram_LM(2, doyle_bigram_counts, doyle_unigram_counts.keys())\n",
    "twain_unigram_lm = ngram_LM(1, twain_unigram_counts, twain_unigram_counts.keys())\n",
    "twain_bigram_lm = ngram_LM(2, twain_bigram_counts, twain_unigram_counts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg1_filename = 'test/seg1.test'\n",
    "seg2_filename = 'test/seg2.test'\n",
    "seg3_filename = 'test/seg3.test'\n",
    "\n",
    "with open(seg1_filename, encoding='utf-8', errors='replace') as f:\n",
    "    # read entire file\n",
    "    seg1_text = f.read() \n",
    "    f.close()\n",
    "\n",
    "with open(seg2_filename, encoding='utf-8', errors='replace') as f:\n",
    "    # read entire file\n",
    "    seg2_text = f.read() \n",
    "    f.close()\n",
    "\n",
    "with open(seg3_filename, encoding='utf-8', errors='replace') as f:\n",
    "    # read entire file\n",
    "    seg3_text = f.read() \n",
    "    f.close()\n",
    "\n",
    "seg1_sent = nltk.sent_tokenize(seg1_text)\n",
    "seg2_sent = nltk.sent_tokenize(seg2_text)\n",
    "seg3_sent = nltk.sent_tokenize(seg3_text)\n",
    "\n",
    "tokenized_seg1 = []\n",
    "tokenized_seg2 = []\n",
    "tokenized_seg3 = []\n",
    "\n",
    "for sent in seg1_sent:\n",
    "    tokenized_seg1.extend(tokenize(sent))\n",
    "    \n",
    "for sent in seg2_sent:\n",
    "    tokenized_seg2.extend(tokenize(sent))\n",
    "    \n",
    "for sent in seg3_sent:\n",
    "    tokenized_seg3.extend(tokenize(sent))\n",
    "\n",
    "seg1_unigrams = word_ngrams(tokenized_seg1, 1)\n",
    "seg2_unigrams = word_ngrams(tokenized_seg2, 1)\n",
    "seg3_unigrams = word_ngrams(tokenized_seg3, 1)\n",
    "\n",
    "seg1_bigrams = word_ngrams(tokenized_seg1, 2)\n",
    "seg2_bigrams = word_ngrams(tokenized_seg2, 2)\n",
    "seg3_bigrams = word_ngrams(tokenized_seg3, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Dickens  Doyle  Twain Predicted Author\n",
      "Seg 1    993.0 1137.9 1098.7          Dickens\n",
      "Seg 2    994.7  690.9 1033.0            Doyle\n",
      "Seg 3    885.5  926.4  546.5            Twain\n"
     ]
    }
   ],
   "source": [
    "seg1_dickens_p_uni = dickens_unigram_lm.perplexity(seg1_unigrams, 0.2)\n",
    "seg1_doyle_p_uni = doyle_unigram_lm.perplexity(seg1_unigrams, 0.2)\n",
    "seg1_twain_p_uni = twain_unigram_lm.perplexity(seg1_unigrams, 0.2)\n",
    "\n",
    "seg2_dickens_p_uni = dickens_unigram_lm.perplexity(seg2_unigrams, 0.2)\n",
    "seg2_doyle_p_uni = doyle_unigram_lm.perplexity(seg2_unigrams, 0.2)\n",
    "seg2_twain_p_uni = twain_unigram_lm.perplexity(seg2_unigrams, 0.2)\n",
    "\n",
    "seg3_dickens_p_uni = dickens_unigram_lm.perplexity(seg3_unigrams, 0.2)\n",
    "seg3_doyle_p_uni = doyle_unigram_lm.perplexity(seg3_unigrams, 0.2)\n",
    "seg3_twain_p_uni = twain_unigram_lm.perplexity(seg3_unigrams, 0.2)\n",
    "\n",
    "table_uni = {}\n",
    "table_uni['Seg 1'] = [seg1_dickens_p_uni, seg1_doyle_p_uni, seg1_twain_p_uni]\n",
    "table_uni['Seg 2'] = [seg2_dickens_p_uni, seg2_doyle_p_uni, seg2_twain_p_uni]\n",
    "table_uni['Seg 3'] = [seg3_dickens_p_uni, seg3_doyle_p_uni, seg3_twain_p_uni]\n",
    "\n",
    "table_uni = pd.DataFrame.from_dict(table_uni, orient='index')\n",
    "table_uni.columns = ['Dickens', 'Doyle', 'Twain']\n",
    "table_uni['Predicted Author'] = table_uni.idxmin(axis=1)\n",
    "pd.set_option('display.float_format', lambda x: '%.1f' % x)\n",
    "print(table_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Dickens  Doyle  Twain Predicted Author\n",
      "Seg 1   1435.2 1713.5 1959.4          Dickens\n",
      "Seg 2   1100.8  418.1 1394.3            Doyle\n",
      "Seg 3   1298.1 1411.9  375.1            Twain\n"
     ]
    }
   ],
   "source": [
    "seg1_dickens_p_bi = dickens_bigram_lm.perplexity(seg1_bigrams, 0.2)\n",
    "seg1_doyle_p_bi = doyle_bigram_lm.perplexity(seg1_bigrams, 0.2)\n",
    "seg1_twain_p_bi = twain_bigram_lm.perplexity(seg1_bigrams, 0.2)\n",
    "\n",
    "seg2_dickens_p_bi = dickens_bigram_lm.perplexity(seg2_bigrams, 0.2)\n",
    "seg2_doyle_p_bi = doyle_bigram_lm.perplexity(seg2_bigrams, 0.2)\n",
    "seg2_twain_p_bi = twain_bigram_lm.perplexity(seg2_bigrams, 0.2)\n",
    "\n",
    "seg3_dickens_p_bi = dickens_bigram_lm.perplexity(seg3_bigrams, 0.2)\n",
    "seg3_doyle_p_bi = doyle_bigram_lm.perplexity(seg3_bigrams, 0.2)\n",
    "seg3_twain_p_bi = twain_bigram_lm.perplexity(seg3_bigrams, 0.2)\n",
    "\n",
    "table_bi = {}\n",
    "table_bi['Seg 1'] = [seg1_dickens_p_bi, seg1_doyle_p_bi, seg1_twain_p_bi]\n",
    "table_bi['Seg 2'] = [seg2_dickens_p_bi, seg2_doyle_p_bi, seg2_twain_p_bi]\n",
    "table_bi['Seg 3'] = [seg3_dickens_p_bi, seg3_doyle_p_bi, seg3_twain_p_bi]\n",
    "\n",
    "table_bi = pd.DataFrame.from_dict(table_bi, orient='index')\n",
    "table_bi.columns = ['Dickens', 'Doyle', 'Twain']\n",
    "table_bi['Predicted Author'] = table_bi.idxmin(axis=1)\n",
    "print(table_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the perplixeties, both the unigram and bigram LMs predicted the authors correctly. This is perhaps due to certain word choices of different authors that cause their word distribution to be similar but different to other authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
